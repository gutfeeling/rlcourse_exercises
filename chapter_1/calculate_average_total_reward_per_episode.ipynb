{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the average total reward per episode in `CartPole-v0` when the agent always takes random actions\n",
    "\n",
    "You already wrote code to take an agent through one episode. Now it is time to do many episodes back to back! And while we are at it, we are also going to compute the average total reward per episode that an agent can expect to get in `CartPole-v0` if it always takes random actions. As you will see, that average total reward is much less than the maximum possible 200.\n",
    "\n",
    "Ready? Here's what I want you to do.\n",
    "\n",
    "1. Set up the `CartPole-v0` environment to the point where it is initialized.\n",
    "2. The agent should take random actions for **1000** episodes. Remember to always reset the environment before starting a new episode.\n",
    "3. Compute the total reward for each episode and store it in a list called `total_rewards`. This list should, of course, we initialized before you begin the episodes. The total reward in an episode is simply the sum of rewards obtained in each time step between the start of the episode and the terminal state.\n",
    "4. At the end of the 1000 episodes, `total_rewards` should have 1000 elements. Now just compute the average total rewards and print it out.\n",
    "\n",
    "Ready? Your code in the cell below. GO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average total rewards over 1000 episodes in CartPole-v0 when the agent takes random actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you successfully computed the average total reward per episode for random actions, then you know that this is way below the maximum total reward of 200. But hey, at least we got started.\n",
    "\n",
    "It is quite obvious that randomly flailing around is not going to get us the maximum rewards. The agent needs to do something smarter. In the next module, we are going to teach the agent how to maximize the rewards and turn it into a pole-balancing circus-performer of our dreams!  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
