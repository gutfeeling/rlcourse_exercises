{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lightweight-requirement",
   "metadata": {},
   "source": [
    "# Implement sampling function for greedy policy with random tie breaking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-vermont",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "You know that a *greedy* policy always picks the action which maximizes the Q-value. \n",
    "\n",
    "Let's say the agent is in a state $s$. There are two actions available: `0` and `1`. Let's say $Q_{\\pi}(s,0)=5$ and $Q_{\\pi}(s,1)=10$. Then under the policy $\\textrm{greedy}(\\pi)$, the agent will always take action `1`, since this maximizes the Q-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-details",
   "metadata": {},
   "source": [
    "## But what happens if there is a tie? \n",
    "\n",
    "Suppose for a state $s$ and policy $\\pi$, both actions have the same Q-value e.g. $Q_{\\pi}(s,0)=5$ and $Q_{\\pi}(s,1)=5$. In this case, there isn't a clear winner. Both actions are equally good.\n",
    "\n",
    "The sampling function for the greedy policy that I wrote in the video will always pick action `0` in this case, because `np.argmax()` returns the first index if there is a tie.\n",
    "\n",
    "Run the cell to load the function into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relevant-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_action_random(observation):\n",
    "    \"\"\"Sampling function for random policy\n",
    "    \"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "def get_action_greedy_policy(observation, q_value_average):\n",
    "    \"\"\"Sampling function for greedy policy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        q_values = np.array([q_value_average[(tuple(observation), action)] for action in (0, 1)])\n",
    "    except KeyError:\n",
    "        return get_action_random(observation)\n",
    "    return np.argmax(q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-lancaster",
   "metadata": {},
   "source": [
    "## We can verify that the above implementation will always return the first index. \n",
    "\n",
    "To verify this, we create a fictitous Q-value dictionary which contains some ties. Run the cell to load the variable `q_value_average_with_ties` into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_value_average_with_ties = {((0.1, 0.1, 0.1, 0.1), 0): 5,    # this state has a tie \n",
    "                             ((0.1, 0.1, 0.1, 0.1), 1): 5,\n",
    "                             ((0.2, 0.2, 0.2, 0.2), 0): 7,    # this state does not have a tie, action 1 has higher Q-value\n",
    "                             ((0.2, 0.2, 0.2, 0.2), 1): 10\n",
    "                             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-wagon",
   "metadata": {},
   "source": [
    "We run `get_action_greedy_policy()` on the tied state `np.array([0.1, 0.1, 0.1, 0.1])` 10 times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extensive-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(get_action_greedy_policy(np.array([0.1, 0.1, 0.1, 0.1]), q_value_average_with_ties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-magnet",
   "metadata": {},
   "source": [
    "It picks `0` every time. This verifies that we are picking the first action (or index) when there is a tie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-bahrain",
   "metadata": {},
   "source": [
    "## Your task in this assignment is to write a better sampling function that breaks ties randomly\n",
    "\n",
    "Picking the first index gives undue preference to the action `0`. When the actions are tied, we should break the tie randomly, i.e choose between `0` and `1` randomly. \n",
    "\n",
    "Reimplement the sampling function for the greedy policy and call it `get_action_greedy_policy_random_tie_break()`. \n",
    "\n",
    "Ready? Your code goes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_greedy_policy_random_tie_break(observation, q_value_average):\n",
    "    # Implement the greedy policy with random tie breaking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-christian",
   "metadata": {},
   "source": [
    "## Check if your implementation works as expected\n",
    "\n",
    "Run the cell below. It will run `get_action_greedy_policy_random_tie_break()` on the tied state `np.array([0.1, 0.1, 0.1, 0.1])` 10 times.\n",
    "\n",
    "If you implementation is correct, it choose `0` some of the times, and `1` at other times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(get_action_greedy_policy_random_tie_break(np.array([0.1, 0.1, 0.1, 0.1]), q_value_average_with_ties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-demonstration",
   "metadata": {},
   "source": [
    "## If you managed to get it working, then kudos to you! Greedy policy with random tie breaks will help the agent make policy improvements and find better and better policies in the environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
