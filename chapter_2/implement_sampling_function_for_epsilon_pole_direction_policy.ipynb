{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the sampling function for a new policy called \"epsilon pole direction policy\"\n",
    "\n",
    "In the last lesson, we implemented the sampling functions for the **random policy** and the **\"pole direction policy\"** for the `CartPole-v0` environment. Here's how they looked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_action_random_policy(observation):\n",
    "    if random.random() < 0.5:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_pole_direction_policy(observation):\n",
    "    if observation[2] > 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wrote a function that computes the average total rewards per episode for any policy. Such a function helps us compare different policies. That function `get_average_total_rewards_per_episode()` is given below.\n",
    "\n",
    "**Study this function carefully.** We are going to need this function frequently in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "\n",
    "def get_average_total_rewards_per_episode(policy_sampling_function, num_episodes):\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    total_rewards = 0\n",
    "    for num_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        while True:\n",
    "            if num_episode == 0:\n",
    "                env.render()\n",
    "            action = policy_sampling_function(observation)\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            total_rewards += reward\n",
    "            if done:\n",
    "                break\n",
    "    env.close()\n",
    "    return total_rewards / num_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then computed the average total rewards for the random policy and the \"pole direction policy\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.436"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for random policy\n",
    "get_average_total_rewards_per_episode(get_action_random_policy, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.723"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for pole direction policy\n",
    "get_average_total_rewards_per_episode(get_action_pole_direction_policy, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearly, the pole direction policy is better than the random policy at getting rewards.\n",
    "\n",
    "| Policy | Average total rewards per episode |\n",
    "| --- | --- |\n",
    "| Random policy | ~ 20 |\n",
    "| Pole direction policy | ~ 40 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here's a question: what if these two policies married and had a baby? How well would the baby do?\n",
    "\n",
    "In this exercise, you are going to implement the sampling function for such a baby policy that is *in-between* these two parent policies. The in-between policy is called \"epsilon pole direction policy\".\n",
    "\n",
    "## The epsilon pole direction policy\n",
    "\n",
    "The epsilon pole direction policy is defined as follows.\n",
    "\n",
    "- With probability $\\epsilon$, the agent takes random actions (i.e. follows the random policy)\n",
    "- With probability $1 - \\epsilon$, the agent moves in the direction of the pole (i.e. follows the \"pole direction policy\")\n",
    "\n",
    "Your job is to implement the sampling function for the epsilon pole direction policy, when $\\epsilon = 0.9$.\n",
    "\n",
    "Ready? Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sampling function for the \"epsilon pole direction policy\", with epsilon = 0.9\n",
    "def get_action_epsilon_pole_direction_policy(observation):\n",
    "    # Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have implemented `get_action_epsilon_pole_direction_policy()`, it's time to find out how much average total rewards this *in-between* policy gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fill in the blank with the correct sampling function to get the average total rewards per episode for the \"epsilon pole direction policy\"\n",
    "get_average_total_rewards_per_episode(____, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on what you found, rank the three policies in the following table by filling in the blanks (____). \n",
    "\n",
    "- The policy with the lowest average total rewards (worst policy) goes in the first row. \n",
    "- The policy with the highest average total rewards (best policy) goes in the last row.\n",
    "\n",
    "| Policy | Average total rewards per episode |\n",
    "| --- | --- |\n",
    "| ____ | ____ |\n",
    "| ____ | ____ |\n",
    "| ____ | ____ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did everything right, you would find that the *in-between* policy (epsilon pole direction policy) is also *in-between* when it comes to total rewards per episodes. \n",
    "\n",
    "**Keep this in mind.** This fact is going to play an important role in a future lesson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
